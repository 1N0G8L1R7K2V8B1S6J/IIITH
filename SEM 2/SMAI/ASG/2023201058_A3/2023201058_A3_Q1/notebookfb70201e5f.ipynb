{"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKzA9qMcerKvpi5yV7cXrv"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"K6W0TP9kKvHA","execution":{"iopub.status.busy":"2024-03-22T07:14:02.269828Z","iopub.execute_input":"2024-03-22T07:14:02.270170Z","iopub.status.idle":"2024-03-22T07:14:03.224562Z","shell.execute_reply.started":"2024-03-22T07:14:02.270142Z","shell.execute_reply":"2024-03-22T07:14:03.223800Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# import torchvision\n# import torchvision.transforms as transforms\n\n# # Define transformation\n# transform = transforms.Compose([\n#     transforms.ToTensor(),\n#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n# ])\n\n# # Load CIFAR-10 dataset\n# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n# trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\n# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n\n# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# import torchvision\n# import torchvision.transforms as transforms\n\n# # Define transformation\n# transform = torchvision.transforms.Compose([\n#     torchvision.transforms.ToTensor(),\n#     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n# ])\n\n# # Load CIFAR-10 dataset\n# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n# trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\n# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n# testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\n# from torchvision import models, datasets, transforms\n\n# Set device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Define transforms for the dataset\ntransform = torchvision.transforms.Compose([\n    # torchvision.transforms.Resize(224),\n#     torchvision.transforms.Resize((224,224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n\n","metadata":{"id":"GIlzXi9y_kKv","execution":{"iopub.status.busy":"2024-03-22T07:45:43.639366Z","iopub.execute_input":"2024-03-22T07:45:43.639968Z","iopub.status.idle":"2024-03-22T07:46:03.122917Z","shell.execute_reply.started":"2024-03-22T07:45:43.639936Z","shell.execute_reply":"2024-03-22T07:46:03.122117Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:08<00:00, 19423476.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define MLP model\nclass MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = self.flatten(x)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# Initialize model, loss function, and optimizer\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmlp_model = MLP().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n\n# Training the model\nfor epoch in range(5):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = mlp_model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n\n# Evaluate the model\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        inputs, labels = data[0].to(device), data[1].to(device)\n        outputs = mlp_model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n","metadata":{"id":"DNigPnw7ho-l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710796259578,"user_tz":-330,"elapsed":169789,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"f333cfc1-e635-43ba-96a7-ebf59017f82d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Files already downloaded and verified\n\nFiles already downloaded and verified\n\nEpoch 1, Loss: 1.6527410385247157\n\nEpoch 2, Loss: 1.4614308119506616\n\nEpoch 3, Loss: 1.357220009245784\n\nEpoch 4, Loss: 1.270260181056332\n\nEpoch 5, Loss: 1.1911689409901527\n\nEpoch 6, Loss: 1.1269549683584896\n\nEpoch 7, Loss: 1.0574596153949973\n\nEpoch 8, Loss: 0.9986916581598979\n\nEpoch 9, Loss: 0.940253328472395\n\nEpoch 10, Loss: 0.8878760070695529\n\nAccuracy of the network on the 10000 test images: 52 %\n"}]},{"cell_type":"code","source":"# Define CNN model\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = self.pool(torch.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 4 * 4)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Initialize model, loss function, and optimizer\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncnn_model = CNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n\n# Training the model\nfor epoch in range(5):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = cnn_model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n\n# Evaluate the model\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        inputs, labels = data[0].to(device), data[1].to(device)\n        outputs = cnn_model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qEAOdmg3Pmgl","executionInfo":{"status":"ok","timestamp":1710788671884,"user_tz":-330,"elapsed":193710,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"a2d28445-8ee4-47b3-88b5-50bd2063dd96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Files already downloaded and verified\n\nFiles already downloaded and verified\n\nEpoch 1, Loss: 1.3555726040195213\n\nEpoch 2, Loss: 0.9396836510165257\n\nEpoch 3, Loss: 0.7715283925725493\n\nEpoch 4, Loss: 0.6535785308993175\n\nEpoch 5, Loss: 0.5640925135146481\n\nEpoch 6, Loss: 0.48523526733606503\n\nEpoch 7, Loss: 0.41329072573611314\n\nEpoch 8, Loss: 0.348453672522928\n\nEpoch 9, Loss: 0.2954901914545457\n\nEpoch 10, Loss: 0.2534648234278478\n\nAccuracy of the network on the 10000 test images: 74 %\n"}]},{"cell_type":"code","source":"# Define transforms for the dataset\ntransform = torchvision.transforms.Compose([\n    # torchvision.transforms.Resize(224),\n    torchvision.transforms.Resize((224,224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n\n# Load pre-trained VGG19 model\nvgg19 = torchvision.models.vgg19(weights='VGG19_Weights.DEFAULT')\nprint(vgg19.features)\nprint(vgg19.features.parameters())\nprint(vgg19.classifier)\n\n# Load pre-trained VGG16 model\nvgg16 = torchvision.models.vgg16(weights='VGG16_Weights.DEFAULT')\nprint(vgg16.features)\nprint(vgg16.features.parameters())\nprint(vgg16.classifier)","metadata":{"execution":{"iopub.status.busy":"2024-03-22T07:58:07.843435Z","iopub.execute_input":"2024-03-22T07:58:07.844005Z","iopub.status.idle":"2024-03-22T07:58:16.497658Z","shell.execute_reply.started":"2024-03-22T07:58:07.843964Z","shell.execute_reply":"2024-03-22T07:58:16.496728Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nSequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (17): ReLU(inplace=True)\n  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (24): ReLU(inplace=True)\n  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (26): ReLU(inplace=True)\n  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (31): ReLU(inplace=True)\n  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (33): ReLU(inplace=True)\n  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (35): ReLU(inplace=True)\n  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n<generator object Module.parameters at 0x7cb1dacea570>\nSequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=1000, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:03<00:00, 161MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (18): ReLU(inplace=True)\n  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (25): ReLU(inplace=True)\n  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (27): ReLU(inplace=True)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n<generator object Module.parameters at 0x7cb1dacea030>\nSequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=1000, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Freeze convolutional layers\nfor param in vgg19.features.parameters():\n    param.requires_grad = False\n\n# Modify the last fully connected layer to output 10 classes\n# num_features = vgg19.classifier[6].in_features\n# features = list(vgg19.classifier.children())[:-1]\n# features.extend([nn.Linear(num_features, 10)])\n# vgg19.classifier = nn.Sequential(*features)\nvgg19.classifier[6] = nn.Linear(vgg19.classifier[6].in_features, 10)\n\n\n# Transfer model to device\nvgg19.to(device)\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(vgg19.parameters(), lr=0.001)\n\n# Train the model\nepochs = 5\nfor epoch in range(epochs):\n    running_loss = 0.0\n    # for inputs, labels in trainloader:\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = vgg19(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        # if i % 100 == 99:    # print every 100 mini-batches\n    print('epoch %d loss: %f' % (epoch + 1, running_loss / len(trainloader)))\n        # running_loss = 0.0\n\n# Evaluate the model\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        inputs, labels = data[0].to(device), data[1].to(device)\n        outputs = vgg19(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RkAowFVPoaF","executionInfo":{"status":"ok","timestamp":1710796037167,"user_tz":-330,"elapsed":3003130,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"7aa0dc79-2d9e-4b20-917d-2c0f0b022609"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Files already downloaded and verified\n\nFiles already downloaded and verified\n\n1 epoch loss: 0.942\n\n2 epoch loss: 0.726\n\n3 epoch loss: 0.640\n\n4 epoch loss: 0.576\n\n5 epoch loss: 0.524\n\n6 epoch loss: 0.467\n\n7 epoch loss: 0.450\n\n8 epoch loss: 0.419\n\n9 epoch loss: 0.388\n\n10 epoch loss: 0.372\n\nFinished Training\n\nAccuracy of the network on the 10000 test images: 81 %\n"}]},{"cell_type":"code","source":"# Define transforms for the dataset\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(224),\n#     torchvision.transforms.Resize((224,224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n\n# # Load pre-trained VGG19 model\n# vgg19 = torchvision.models.vgg19(weights='VGG19_Weights.DEFAULT')\n# print(vgg19.features)\n# print(vgg19.features.parameters())\n# print(vgg19.classifier)","metadata":{"execution":{"iopub.status.busy":"2024-03-22T07:58:44.356081Z","iopub.execute_input":"2024-03-22T07:58:44.356898Z","iopub.status.idle":"2024-03-22T07:58:47.804776Z","shell.execute_reply.started":"2024-03-22T07:58:44.356860Z","shell.execute_reply":"2024-03-22T07:58:47.803897Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nSequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (17): ReLU(inplace=True)\n  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (24): ReLU(inplace=True)\n  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (26): ReLU(inplace=True)\n  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (31): ReLU(inplace=True)\n  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (33): ReLU(inplace=True)\n  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (35): ReLU(inplace=True)\n  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n<generator object Module.parameters at 0x7cb1dacea570>\nSequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=1000, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Freeze convolutional layers\nfor param in vgg19.features[:29].parameters():\n    param.requires_grad = False\n\nfor param in vgg19.features[29:].parameters():\n    param.requires_grad = True\n\n# Modify the last fully connected layer to output 10 classes\n# num_features = vgg19.classifier[6].in_features\n# features = list(vgg19.classifier.children())[:-1]\n# features.extend([nn.Linear(num_features, 10)])\n# vgg19.classifier = nn.Sequential(*features)\nvgg19.classifier[6] = nn.Linear(vgg19.classifier[6].in_features, 10)\n\n\n# Transfer model to device\nvgg19.to(device)\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(vgg19.parameters(), lr=0.001)\n\n# Train the model\nepochs = 5\nfor epoch in range(epochs):\n    running_loss = 0.0\n    # for inputs, labels in trainloader:\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = vgg19(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        # if i % 100 == 99:    # print every 100 mini-batches\n    print('epoch %d loss: %f' % (epoch + 1, running_loss / len(trainloader)))\n        # running_loss = 0.0\n\n# Evaluate the model\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        inputs, labels = data[0].to(device), data[1].to(device)\n        outputs = vgg19(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710796037167,"user_tz":-330,"elapsed":3003130,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"7aa0dc79-2d9e-4b20-917d-2c0f0b022609","id":"zCyAEkzaH2bI","execution":{"iopub.status.busy":"2024-03-22T07:58:47.806241Z","iopub.execute_input":"2024-03-22T07:58:47.806519Z","iopub.status.idle":"2024-03-22T08:20:54.596271Z","shell.execute_reply.started":"2024-03-22T07:58:47.806493Z","shell.execute_reply":"2024-03-22T08:20:54.595265Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"epoch 1 loss: 0.918857\nepoch 2 loss: 0.596899\nepoch 3 loss: 0.527485\nepoch 4 loss: 0.460002\nepoch 5 loss: 0.451776\nAccuracy of the network on the 10000 test images: 81 %\n","output_type":"stream"}]}]}