{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOoZqo0Wwm9VlRbLGE9qLnf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"id":"K6W0TP9kKvHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","# import torch.optim as optim\n","# import torchvision\n","# import torchvision.transforms as transforms\n","\n","# # Define transformation\n","# transform = transforms.Compose([\n","#     transforms.ToTensor(),\n","#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","# ])\n","\n","# # Load CIFAR-10 dataset\n","# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","# trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n","\n","# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","# testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n","\n","# import torch\n","# import torch.nn as nn\n","# import torch.optim as optim\n","# import torchvision\n","# import torchvision.transforms as transforms\n","\n","# # Define transformation\n","# transform = torchvision.transforms.Compose([\n","#     torchvision.transforms.ToTensor(),\n","#     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","# ])\n","\n","# # Load CIFAR-10 dataset\n","# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","# trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n","\n","# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","# testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","# from torchvision import models, datasets, transforms\n","\n","# Set device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define transforms for the dataset\n","transform = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(224),\n","    # torchvision.transforms.Resize((224,224)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n","\n","# Load CIFAR-10 dataset\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIlzXi9y_kKv","executionInfo":{"status":"ok","timestamp":1711045718147,"user_tz":-330,"elapsed":2037,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"08c4d9fc-058d-40af-b350-caca8c08a7f8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"DNigPnw7ho-l","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1711045720804,"user_tz":-330,"elapsed":10,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"eb20a184-c864-49f8-ef2e-532de7f52b1e"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x150528 and 3072x512)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-38b1b7ba7955>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-38b1b7ba7955>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x150528 and 3072x512)"]}],"source":["# Define MLP model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Initialize model, loss function, and optimizer\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","mlp_model = MLP().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n","\n","# Training the model\n","for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = mlp_model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n","\n","# Evaluate the model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        outputs = mlp_model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"]},{"cell_type":"code","source":["# Define CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n","        self.fc2 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = self.pool(torch.relu(self.conv3(x)))\n","        x = x.view(-1, 64 * 4 * 4)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Initialize model, loss function, and optimizer\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","cnn_model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n","\n","# Training the model\n","for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = cnn_model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n","\n","# Evaluate the model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        outputs = cnn_model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qEAOdmg3Pmgl","executionInfo":{"status":"ok","timestamp":1710788671884,"user_tz":-330,"elapsed":193710,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"a2d28445-8ee4-47b3-88b5-50bd2063dd96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch 1, Loss: 1.3555726040195213\n","Epoch 2, Loss: 0.9396836510165257\n","Epoch 3, Loss: 0.7715283925725493\n","Epoch 4, Loss: 0.6535785308993175\n","Epoch 5, Loss: 0.5640925135146481\n","Epoch 6, Loss: 0.48523526733606503\n","Epoch 7, Loss: 0.41329072573611314\n","Epoch 8, Loss: 0.348453672522928\n","Epoch 9, Loss: 0.2954901914545457\n","Epoch 10, Loss: 0.2534648234278478\n","Accuracy of the network on the 10000 test images: 74 %\n"]}]},{"cell_type":"code","source":["# Load pre-trained VGG19 model\n","vgg19 = torchvision.models.vgg19(weights='VGG19_Weights.DEFAULT')\n","\n","# Freeze convolutional layers\n","for param in vgg19.features.parameters():\n","    param.requires_grad = False\n","\n","# Modify the last fully connected layer to output 10 classes\n","# num_features = vgg19.classifier[6].in_features\n","# features = list(vgg19.classifier.children())[:-1]\n","# features.extend([nn.Linear(num_features, 10)])\n","# vgg19.classifier = nn.Sequential(*features)\n","vgg19.classifier[6] = nn.Linear(vgg19.classifier[6].in_features, 10)\n","\n","\n","# Transfer model to device\n","vgg19.to(device)\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(vgg19.parameters(), lr=0.001)\n","\n","# Train the model\n","epochs = 10\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    # for inputs, labels in trainloader:\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = vgg19(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        # if i % 100 == 99:    # print every 100 mini-batches\n","    print('epoch %d loss: %f' % (epoch + 1, running_loss / len(trainloader)))\n","        # running_loss = 0.0\n","\n","# Evaluate the model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        outputs = vgg19(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RkAowFVPoaF","executionInfo":{"status":"ok","timestamp":1710796037167,"user_tz":-330,"elapsed":3003130,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"7aa0dc79-2d9e-4b20-917d-2c0f0b022609"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","1 epoch loss: 0.942\n","2 epoch loss: 0.726\n","3 epoch loss: 0.640\n","4 epoch loss: 0.576\n","5 epoch loss: 0.524\n","6 epoch loss: 0.467\n","7 epoch loss: 0.450\n","8 epoch loss: 0.419\n","9 epoch loss: 0.388\n","10 epoch loss: 0.372\n","Finished Training\n","Accuracy of the network on the 10000 test images: 81 %\n"]}]},{"cell_type":"code","source":["# Load pre-trained VGG19 model\n","vgg19 = torchvision.models.vgg19(weights='VGG19_Weights.DEFAULT')\n","\n","# Freeze convolutional layers\n","for param in vgg19.features[:20].parameters():\n","    param.requires_grad = False\n","\n","for param in vgg19.features[20:].parameters():\n","    param.requires_grad = True\n","\n","# Modify the last fully connected layer to output 10 classes\n","# num_features = vgg19.classifier[6].in_features\n","# features = list(vgg19.classifier.children())[:-1]\n","# features.extend([nn.Linear(num_features, 10)])\n","# vgg19.classifier = nn.Sequential(*features)\n","vgg19.classifier[6] = nn.Linear(vgg19.classifier[6].in_features, 10)\n","\n","\n","# Transfer model to device\n","vgg19.to(device)\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(vgg19.parameters(), lr=0.001)\n","\n","# Train the model\n","epochs = 10\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    # for inputs, labels in trainloader:\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = vgg19(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        # if i % 100 == 99:    # print every 100 mini-batches\n","    print('epoch %d loss: %f' % (epoch + 1, running_loss / len(trainloader)))\n","        # running_loss = 0.0\n","\n","# Evaluate the model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        outputs = vgg19(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710796037167,"user_tz":-330,"elapsed":3003130,"user":{"displayName":"Hemanth Reddy","userId":"09263723995373073861"}},"outputId":"7aa0dc79-2d9e-4b20-917d-2c0f0b022609","id":"zCyAEkzaH2bI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","1 epoch loss: 0.942\n","2 epoch loss: 0.726\n","3 epoch loss: 0.640\n","4 epoch loss: 0.576\n","5 epoch loss: 0.524\n","6 epoch loss: 0.467\n","7 epoch loss: 0.450\n","8 epoch loss: 0.419\n","9 epoch loss: 0.388\n","10 epoch loss: 0.372\n","Finished Training\n","Accuracy of the network on the 10000 test images: 81 %\n"]}]}]}